{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import os\n",
    "        \n",
    "imgs_path = './data/hw3_mycocodata_img_comp_zlib.h5'\n",
    "masks_path = './data/hw3_mycocodata_mask_comp_zlib.h5'\n",
    "labels_path = './data/hw3_mycocodata_labels_comp_zlib.npy'\n",
    "bboxes_path = './data/hw3_mycocodata_bboxes_comp_zlib.npy'\n",
    "paths = [imgs_path, masks_path, labels_path, bboxes_path]\n",
    "    \n",
    "img_path, mask_path, label_path, bbox_path = paths\n",
    "\n",
    "# Loading the data\n",
    "with h5py.File(img_path, 'r') as file:\n",
    "    gb_images = file[list(file.keys())[0]][:30]\n",
    "with h5py.File(mask_path, 'r') as file:\n",
    "    gb_masks = file[list(file.keys())[0]][:100]\n",
    "gb_labels = np.load(label_path, allow_pickle=True)[:30]\n",
    "gb_bboxes = np.load(bbox_path, allow_pickle=True)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Author: Lishuo Pan 2020/4/18\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import os\n",
    "\n",
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths):\n",
    "        # Paths to the data\n",
    "        img_path, mask_path, label_path, bbox_path = paths\n",
    "        \n",
    "        # Loading the data\n",
    "        # with h5py.File(img_path, 'r') as file:\n",
    "        #     self.images = file[list(file.keys())[0]][:]\n",
    "        # with h5py.File(mask_path, 'r') as file:\n",
    "        #     self.masks = file[list(file.keys())[0]][:]\n",
    "        # self.labels = np.load(label_path, allow_pickle=True)\n",
    "        # self.bboxes = np.load(bbox_path, allow_pickle=True)\n",
    "        \n",
    "        self.images = gb_images\n",
    "        self.labels = gb_labels\n",
    "        self.bboxes = gb_bboxes\n",
    "        self.masks = gb_masks\n",
    "\n",
    "        # Match masks to images\n",
    "        self.match_masks_to_images()\n",
    "\n",
    "    def calculate_mask_bounding_box(self, mask):\n",
    "        \"\"\"Calculate the bounding box of the non-zero elements in a binary mask.\"\"\"\n",
    "        rows = np.any(mask, axis=0)\n",
    "        cols = np.any(mask, axis=1)\n",
    "        ymin, ymax = np.where(rows)[0][[0, -1]]\n",
    "        xmin, xmax = np.where(cols)[0][[0, -1]]\n",
    "        return xmin, ymin, xmax, ymax\n",
    "\n",
    "    def match_masks_to_images(self):\n",
    "        \"\"\"Match masks to images based on the bounding boxes.\"\"\"\n",
    "        self.matched_images = []\n",
    "        self.matched_masks = []\n",
    "        self.matched_labels = []\n",
    "        self.matched_bboxes = []\n",
    "\n",
    "\n",
    "        for i, label in enumerate(self.labels):  # Assuming labels[i] corresponds to image i\n",
    "            n_obj = len(label)\n",
    "            curr_masks = []\n",
    "            for j in range(n_obj):\n",
    "                \n",
    "                mask = self.masks[10]\n",
    "                \n",
    "                curr_masks.append(mask)\n",
    "            \n",
    "            curr_masks = (curr_masks)\n",
    "            self.matched_masks.append(curr_masks)\n",
    "            self.matched_images.append(self.images[i])\n",
    "            self.matched_labels.append(self.labels[i])\n",
    "            self.matched_bboxes.append(self.bboxes[i])\n",
    "            \n",
    "            if i == 10:\n",
    "                break\n",
    "            \n",
    "        self.matched_masks = np.array(self.matched_masks, dtype=object)\n",
    "        self.matched_images = np.array(self.matched_images)\n",
    "        self.matched_labels = np.array(self.matched_labels, dtype=object)\n",
    "        self.matched_bboxes = np.array(self.matched_bboxes, dtype=object)\n",
    "            \n",
    "        print(len(self.matched_images), len(self.matched_masks), len(self.masks))\n",
    "\n",
    "\n",
    "\n",
    "    # output:\n",
    "        # transed_img\n",
    "        # label\n",
    "        # transed_mask\n",
    "        # transed_bbox\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # TODO: __getitem__\n",
    "\n",
    "        # check flag\n",
    "        # print(self.images.shape)\n",
    "        img = self.matched_images[index]\n",
    "        mask = self.matched_masks[index]\n",
    "        bbox = self.matched_bboxes[index]\n",
    "        label = self.matched_labels[index]\n",
    "\n",
    "    \n",
    "        tensor = torch.tensor(img)\n",
    "        \n",
    "        if tensor.dtype != torch.float32:\n",
    "            tensor = tensor.float()\n",
    "\n",
    "        tensor = F.interpolate(tensor.unsqueeze(0), size=(800, 1066), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "        tensor = transforms.functional.normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        # print(tensor.shape)\n",
    " \n",
    "        \n",
    "        tensor = F.pad(tensor, (11, 11, 0, 0), \"constant\", 0)\n",
    "\n",
    "        \n",
    "\n",
    "        # print(list(tensor.shape))\n",
    "        assert list(tensor.shape) == [3, 800, 1088]\n",
    "        \n",
    "        assert bbox.shape[0] == mask.shape[0]\n",
    "        \n",
    "        return tensor, label, mask, bbox\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.matched_images)\n",
    "    \n",
    "\n",
    "    # This function take care of the pre-process of img,mask,bbox\n",
    "    # in the input mini-batch\n",
    "    # input:\n",
    "        # img: 3*300*400\n",
    "        # mask: 3*300*400\n",
    "        # bbox: n_box*4\n",
    "    def pre_process_batch(self, img, mask, bbox):\n",
    "        # TODO: image preprocess\n",
    "\n",
    "        # check flag\n",
    "        assert img.shape == (3, 800, 1088)\n",
    "        assert bbox.shape[0] == mask.squeeze(0).shape[0]\n",
    "        return img, mask, bbox\n",
    "\n",
    "\n",
    "class BuildDataLoader(torch.utils.data.DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle, num_workers):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        # Initialize the DataLoader with the custom collect function\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=self.shuffle,\n",
    "                                     num_workers=self.num_workers, collate_fn=self.collect_fn)\n",
    "\n",
    "\n",
    "    # output:\n",
    "        # img: (bz, 3, 800, 1088)\n",
    "        # label_list: list, len:bz, each (n_obj,)\n",
    "        # transed_mask_list: list, len:bz, each (n_obj, 800,1088)\n",
    "        # transed_bbox_list: list, len:bz, each (n_obj, 4)\n",
    "        # img: (bz, 3, 300, 400)\n",
    "    def collect_fn(self, batch):\n",
    "        transed_img_list = []\n",
    "        label_list = []\n",
    "        transed_mask_list = []\n",
    "        transed_bbox_list = []\n",
    "        \n",
    "        for transed_img, label, transed_mask, transed_bbox in batch:\n",
    "            transed_img_list.append(transed_img)\n",
    "            label_list.append(label)\n",
    "            transed_mask_list.append(transed_mask)\n",
    "            transed_bbox_list.append(transed_bbox)\n",
    "            \n",
    "        return torch.stack(transed_img_list, dim=0), label_list, transed_mask_list, transed_bbox_list\n",
    "\n",
    "\n",
    "    def loader(self):\n",
    "        return self.dataloader\n",
    "\n",
    "## Visualize debugging\n",
    "if __name__ == '__main__':\n",
    "    # file path and make a list\n",
    "    imgs_path = './data/hw3_mycocodata_img_comp_zlib.h5'\n",
    "    masks_path = './data/hw3_mycocodata_mask_comp_zlib.h5'\n",
    "    labels_path = './data/hw3_mycocodata_labels_comp_zlib.npy'\n",
    "    bboxes_path = './data/hw3_mycocodata_bboxes_comp_zlib.npy'\n",
    "    paths = [imgs_path, masks_path, labels_path, bboxes_path]\n",
    "    # load the data into data.Dataset\n",
    "    dataset = BuildDataset(paths)\n",
    "\n",
    "    ## Visualize debugging\n",
    "    # --------------------------------------------\n",
    "    # build the dataloader\n",
    "    # set 20% of the dataset as the training data\n",
    "    full_size = len(dataset)\n",
    "    train_size = int(full_size * 0.8)\n",
    "    test_size = full_size - train_size\n",
    "    # random split the dataset into training and testset\n",
    "    # set seed\n",
    "    torch.random.manual_seed(1)\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    # push the randomized training data into the dataloader\n",
    "\n",
    "    batch_size = 2\n",
    "    train_build_loader = BuildDataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    train_loader = train_build_loader.loader()\n",
    "    test_build_loader = BuildDataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader = test_build_loader.loader()\n",
    "\n",
    "    mask_color_list = [\"jet\", \"ocean\", \"Spectral\", \"spring\", \"cool\"]\n",
    "    # loop the image\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    for iter, data in enumerate(train_loader, 0):\n",
    "\n",
    "        img, label, mask, bbox = [data[i] for i in range(len(data))]\n",
    "        # check flag\n",
    "        assert img.shape == (batch_size, 3, 800, 1088)\n",
    "        assert len(mask) == batch_size\n",
    "\n",
    "        label = [label_img.to(device) for label_img in label]\n",
    "        mask = [mask_img.to(device) for mask_img in mask]\n",
    "        bbox = [bbox_img.to(device) for bbox_img in bbox]\n",
    "\n",
    "\n",
    "        # plot the origin img\n",
    "        for i in range(batch_size):\n",
    "            ## TODO: plot images with annotations\n",
    "            plt.savefig(\"./testfig/visualtrainset\"+str(iter)+\".png\")\n",
    "            plt.show()\n",
    "\n",
    "        if iter == 10:\n",
    "            break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
